


**************************************************************************************************************************************************************************************
****************** Run: run.py | Framework: PyTorch | Method: rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres | Version: 1 | Data: CholecT50 | Batch: 1 ******************
*** Time: Fri Sep 22 10:32:20 2023 | Start: 0-epoch  0-steps | Init CKPT: None | Save CKPT: ./__checkpoint__/run_1/rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres.pth ***
*********** LR Config: Init: [0.01, 0.01, 0.01] | Peak: [0.1, 0.1, 0.1] | Warmup Epoch: [9, 18, 58] | Rise: 0.1 | Decay 0.99 | train params 17120331 | all params 17120331 ***********
**************************************************************************************************************************************************************************************



**************************************************************************************************************************************************************************************
***************** Run: run.py | Framework: PyTorch | Method: rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres | Version: 1 | Data: CholecT50 | Batch: 256 *****************
*** Time: Fri Sep 22 10:37:17 2023 | Start: 0-epoch  0-steps | Init CKPT: None | Save CKPT: ./__checkpoint__/run_1/rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres.pth ***
*********** LR Config: Init: [0.01, 0.01, 0.01] | Peak: [0.1, 0.1, 0.1] | Warmup Epoch: [9, 18, 58] | Rise: 0.1 | Decay 0.99 | train params 17120331 | all params 17120331 ***********
**************************************************************************************************************************************************************************************
--------------------------------------------------
Test Results
Per-category AP: 
I   : [0.91737279 0.11451246 0.60578477 0.04578504 0.02819404 0.05874513]
V   : [0.10769701 0.70948831 0.51378531 0.08404713 0.03069868 0.02509149
 0.04516958 0.02251081 0.01766796 0.11955304]
T   : [0.64050507 0.08022102 0.10975527 0.05532456 0.0080752         nan
 0.04382058 0.01320809 0.2252051  0.10173296 0.09195894 0.03494369
 0.01660584 0.08247934 0.10845225]
IV  : [0.09735272 0.77975889 0.01078842 0.00613499 0.05103854 0.07821739
 0.01568282 0.01677953 0.06753423 0.01218429 0.0133198  0.5193587
 0.00862585        nan 0.03488991        nan        nan 0.02831269
 0.00918375 0.02389837 0.00920675 0.00975586        nan 0.04722443
 0.01596713 0.01218228]
IT  : [0.57895885 0.03757857 0.01756131 0.01233245        nan 0.15889494
 0.09489904 0.01524852 0.03079114 0.05942408 0.05103854 0.01789361
 0.01835372 0.0130857         nan 0.0054135         nan 0.02322712
 0.07279745        nan 0.014558          nan        nan 0.01218429
 0.28016754 0.07379065 0.06505299 0.04248116        nan        nan
 0.01246346 0.09931545 0.02581848 0.03488991        nan 0.00490466
 0.0110574  0.02058099        nan 0.040289   0.04776255        nan
        nan 0.00918375 0.00377468 0.01449697 0.01502232        nan
        nan 0.00920675        nan        nan        nan 0.01256888
 0.04722443 0.00984612 0.01168159        nan 0.01218228]
IVT : [       nan 0.00494236 0.01408451 0.01233245 0.01440207        nan
 0.00703928 0.0314846  0.02204114 0.03294735 0.03581733        nan
 0.05942408 0.00613499        nan        nan 0.05865514 0.5792456
 0.01480338 0.15622515 0.11587759 0.0149808  0.02322712        nan
        nan 0.01721204 0.0054135  0.02483915 0.01067965 0.04293263
 0.02752686        nan        nan        nan 0.00734924        nan
 0.01615253        nan 0.00409935 0.11642701        nan 0.00254043
        nan        nan 0.01516423 0.0131085         nan        nan
        nan        nan        nan 0.00543453 0.00956174 0.01326202
        nan        nan        nan 0.04251091 0.06505085 0.08369729
 0.28435404 0.04862488 0.02442895 0.010856   0.01325944        nan
 0.04776255        nan 0.02058099 0.0110574  0.00887815 0.040289
        nan        nan        nan        nan        nan        nan
 0.01502232 0.01449697        nan 0.00377468 0.04722443        nan
        nan        nan        nan        nan 0.00984612 0.01256888
 0.00713493        nan 0.00980703        nan 0.05103854 0.01218429
 0.03488991 0.00918375 0.00920675 0.01218228]
--------------------------------------------------
Mean AP:  I  |  V  |  T  |  IV  |  IT  |  IVT 
:::::: : 0.2951 | 0.1676 | 0.1152 | 0.0849 | 0.0521 | 0.0407 
==================================================
All done!
Shutting done...
It is what it is ...
C'est finis! --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------



**************************************************************************************************************************************************************************************
***************** Run: run.py | Framework: PyTorch | Method: rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres | Version: 1 | Data: CholecT50 | Batch: 256 *****************
*** Time: Sat Sep 23 13:49:00 2023 | Start: 0-epoch  0-steps | Init CKPT: None | Save CKPT: ./__checkpoint__/run_1/rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres.pth ***
*********** LR Config: Init: [0.01, 0.01, 0.01] | Peak: [0.1, 0.1, 0.1] | Warmup Epoch: [9, 18, 58] | Rise: 0.1 | Decay 0.99 | train params 17120331 | all params 17120331 ***********
**************************************************************************************************************************************************************************************
--------------------------------------------------
Test Results
Per-category AP: 
I   : [0.93172074 0.88094667 0.97578476 0.53831935 0.79775358 0.73923277]
V   : [0.60983174 0.90219925 0.9356883  0.74758086 0.77002908 0.57164763
 0.53500757 0.17919599 0.10576215 0.2394841 ]
T   : [0.87777872 0.13776331 0.20382943 0.19719872 0.01905324        nan
 0.55963382 0.11834715 0.59896735 0.0998659  0.47193542 0.20717993
 0.03971312 0.72602974 0.21073383]
IV  : [0.56568862 0.8822     0.00187062 0.00719196 0.16512606 0.01955661
 0.03744586 0.06639081 0.59303768 0.03071306 0.02146548 0.88494835
 0.01007036        nan 0.07906628        nan        nan 0.15723599
 0.01709311 0.41537074 0.06599333 0.053124          nan 0.51124861
 0.13531274 0.0767578 ]
IT  : [0.78741345 0.03325919 0.05597012 0.01424202        nan 0.56880331
 0.36681429 0.0692766  0.0490786  0.70168943 0.16512606 0.08008239
 0.1178486  0.02300503        nan 0.01209741        nan 0.07782208
 0.61893755        nan 0.15898217        nan        nan 0.03071306
 0.6735682  0.18442732 0.18337913 0.10432548        nan        nan
 0.00611162 0.34740655 0.04706098 0.07906628        nan 0.00386828
 0.04255084 0.13901232        nan 0.0389475  0.07162575        nan
        nan 0.01709311 0.00637401 0.2844153  0.34637358        nan
        nan 0.06599333        nan        nan        nan 0.00253472
 0.51124861 0.07133747 0.07928117        nan 0.0767578 ]
IVT : [       nan 0.00327753 0.0008658  0.01424202 0.0172203         nan
 0.00708397 0.14624763 0.00442389 0.0106653  0.0130948         nan
 0.70168943 0.00719196        nan        nan 0.04625702 0.78898526
 0.04632107 0.56999354 0.36416021 0.08047235 0.07782208        nan
        nan 0.03879893 0.011967   0.11967123 0.08520843 0.59575517
 0.29486216        nan        nan        nan 0.00137239        nan
 0.06862334        nan 0.00461818 0.04002146        nan 0.01315431
        nan        nan 0.00704794 0.00276903        nan        nan
        nan        nan        nan 0.00578807 0.00311203 0.02857656
        nan        nan        nan 0.10432609 0.18362549 0.18450441
 0.66593674 0.3323793  0.04721727 0.02132396 0.01020131        nan
 0.07162575        nan 0.13901232 0.04255084 0.00416519 0.0389475
        nan        nan        nan        nan        nan        nan
 0.34637358 0.2844153         nan 0.00637401 0.51124861        nan
        nan        nan        nan        nan 0.07133747 0.00226677
 0.18200236        nan 0.05537162        nan 0.16512606 0.03071306
 0.07906628 0.01709311 0.06599333 0.0767578 ]
--------------------------------------------------
Mean AP:  I  |  V  |  T  |  IV  |  IT  |  IVT 
:::::: : 0.8106 | 0.5596 | 0.3191 | 0.2180 | 0.1784 | 0.1305 
==================================================
All done!
Shutting done...
It is what it is ...
C'est finis! --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------



**************************************************************************************************************************************************************************************
***************** Run: run.py | Framework: PyTorch | Method: rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres | Version: 1 | Data: CholecT50 | Batch: 64 *****************
*** Time: Thu Nov  9 11:24:19 2023 | Start: 0-epoch  0-steps | Init CKPT: None | Save CKPT: ./__checkpoint__/run_1/rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres.pth ***
*********** LR Config: Init: [0.01, 0.01, 0.01] | Peak: [0.1, 0.1, 0.1] | Warmup Epoch: [9, 18, 58] | Rise: 0.1 | Decay 0.99 | train params 17120331 | all params 17120331 ***********
**************************************************************************************************************************************************************************************
